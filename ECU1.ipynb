{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Claudita22/nuevo_repositorio/blob/main/ECU1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Claudia Guadalupe Quezada Lopez"
      ],
      "metadata": {
        "id": "v6PzZW_GFgdr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk84YrxF7PMV"
      },
      "outputs": [],
      "source": [
        "!uv pip install -q --system \"numba-cuda==0.4.0\"\n",
        "!pip install -q --extra-index-url https://pypi.nvidia.com pynvjitlink-cu12\n",
        "from numba import config, cuda\n",
        "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def first_kernel(a, result):\n",
        "  idx = cuda.grid(1)\n",
        "  if idx < a.size:\n",
        "    result[idx] = a[idx]\n",
        "\n",
        "# Host\n",
        "def main():\n",
        "  #2. Initialize data on CPU\n",
        "  N = 10_000_000\n",
        "  a_cpu = np.arange(N, dtype=np.float32)\n",
        "\n",
        "  # -------------------------------------\n",
        "  # CPU Computation\n",
        "  #--------------------------------------\n",
        "  start = time.time()\n",
        "  result_cpu = a_cpu\n",
        "  cpu_time = time.time() - start\n",
        "  print(f\"CPU time: {cpu_time * 1e3:.2f} ms\")\n",
        "\n",
        "  #----------------------------------------\n",
        "  # GPU coputation\n",
        "  #----------------------------------------\n",
        "  # 2. Transfer from CPU to GPU\n",
        "  start = time.time()\n",
        "  a_gpu = cuda.to_device(a_cpu)\n",
        "  result_gpu = cuda.device_array_like(a_cpu) #reserve memoria\n",
        "  transfer_in_time = time.time() - start\n",
        "\n",
        "  # Kernel launch\n",
        "  threads_per_block = 128\n",
        "  blocks_per_grid = (N + threads_per_block -1) // threads_per_block\n",
        "  start = time.time()\n",
        "  first_kernel[blocks_per_grid, threads_per_block](a_gpu, result_gpu)\n",
        "  cuda.synchronize()\n",
        "  kernel_time = time.time() - start\n",
        "\n",
        "  # Copy Back\n",
        "  start = time.time()\n",
        "  result_from_gpu = result_gpu.copy_to_host()\n",
        "  cuda.synchronize()\n",
        "  transfer_out_time = time.time() - start\n",
        "\n",
        "  # Report\n",
        "  print(f\"GPU transfer to device: {transfer_in_time * 1e3:.2f} ms\")\n",
        "  print(f\"GPU kernel execution:   {kernel_time * 1e3:.2f} ms\")\n",
        "  print(f\"GPU transfer to host:   {transfer_out_time * 1e3:.2f} ms\")\n",
        "  print(f\"Total GPU time:         {(transfer_in_time + kernel_time + transfer_out_time) * 1e3:.2f} ms\")\n",
        "\n",
        "  # Cleanup\n",
        "  del a_gpu, result_gpu\n",
        "  cuda.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ],
      "metadata": {
        "id": "QIKlISbC9qFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}